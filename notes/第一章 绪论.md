---
title: 第一章 绪论
created: '2021-10-03T17:23:56.981Z'
modified: '2021-10-05T07:48:24.791Z'
---

# 第一章 绪论
## 1. 引言
### 什么是机器学习？
* 机器学习致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。
* 机器学习所研究的主要内容，是关于在计算机上从数据中产生“模型”的算法，即“学习算法”。
* “模型”泛指从数据中学得的结果
## 2. 基本术语
* **数据**：色泽 = 青绿，“=”意思是“取值为”
* **数据集**：记录的集合
* **示例（样本）**：每条记录是关于一个事件或对象的描述，称为一个示例或样本
* **属性（特征）**：反映事件或对象在某方面的表现或性质（色泽）
* **属性值**：属性上的取值
* **属性空间、样本空间或输入空间**：属性张成的空间
* **特征向量**：每个事件或对象都可以在样本空间中找到自己的坐标，对应一个坐标向量
* **维数**：描述的属性的个数
* **训练集**：训练过程中使用的数据
* **标记**：训练样本的“结果”信息
* **样例**：拥有了标记信息的示例(xi,yi),yi是示例xi的标记
* **分类**：若欲预测的是离散值，此类学习任务称为“分类”
* **回归**：若欲预测的是连续值，此类学习任务称为“分类”
* **测试**：学得模型后，使用其进行预测的过程，被测试的样本称为“测试样本”
* **聚类**：将训练集中的西瓜分成若干“簇”，训练样本不拥有标记信息
* **监督学习**：训练数据有标记信息，如分类和回归
* **无监督学习**：巡礼数据没有标记信息，如聚类
* **“泛化”能力**：学得模型适用于新样本的能力
## 3. 假设空间
* **归纳**：从特殊到一般的“泛化”过程，即从具体的事实归结出一般性规律。
> **狭义**：狭义的归纳学习要求从训练数据中学得概念
> **广义**：广义的归纳学习大体相当于从样例中学习
### 学习过程
* 看作一个在所有假设（hypothesis）组成的空间中进行搜索的过程，搜索目标是找到与训练集“匹配”（fit）的假设
### 假设空间
* 假设的表示一旦确定，假设空间及其规模大小就确定了，如：（色泽=？） ^ （根蒂=？） ^ （敲声=？）
* 假设每个属性分别都有3种可能的取值，则上述假设空间的规模为：4 x 4 x 4 + 1 = 65
* **版本空间**：一个与训练集一致的“假设集合”
## 4. 归纳偏好
### 问题：
* 通过学习得到的模型对应了假设空间中的一个假设，但对应的模型在面临新样本的时候，采用不同的假设可能会产生**不同的输出**。需要判断采用哪一个模型（假设）。
### 解决方法：
* 对于一个具体的学习算法而言，它必须要产生一个模型。这时，学习算法本身的**偏好**就会起到关键的作用。
* 任何一个有效的学习算法必有其归纳偏好，否则它将被假设空间中看似在训练集上“等效”的假设所迷惑，而无法产生确定的学习结果。
* 如果没有偏好，产生的模型每次在进行判断时随机抽选训练集上的等效假设，每次的结果都不同，这样的学习结果显然没有意义。
### 确定“正确”偏好的一般性原则：
* **奥卡姆剃刀**：若有多个假设与观察一致，则选最简单的那个
* 奥卡姆剃刀并非唯一可行的原则，奥卡姆剃刀本身存在不同的诠释。“哪个更简单”这个问题可能需要借助其他机制才能解决。
* 归纳偏好对应了学习算法本身所作出的关于”什么样的模型更好“的假设。算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好的性能。
### “没有免费的午餐”定理
* 当所有问题出现的机会相同，或所有问题同等重要时，总误差与学习算法无关，所有算法的期望性相同。
* 但很多时候，我们只关注自己正在试图解决的问题，至于这个解决方案在别的问题，甚至在相似的问题上是否为好方案，我们并不关心。
* **NFL定理最重要的寓意**：脱离具体问题，空谈“什么学习算法更好”毫无意义
## 5. 发展历程
## 6. 应用现状
## 7. 阅读材料
